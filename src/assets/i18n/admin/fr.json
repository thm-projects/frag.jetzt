{
  "overview": {
    "motd": "Annonces globales",
    "gpt": "Paramètres GPT",
    "gpt-chat": "Chat avec GPT"
  },
  "create-motd": {
    "create": "Créer",
    "english": "Texte anglais",
    "error": "Une erreur s'est produite !",
    "french": "Texte français",
    "german": "Texte allemand",
    "label": "Date de début et de fin",
    "placeholder-date-end": "Date de fin",
    "placeholder-date-start": "Date de début",
    "placeholder-english": "Entrer ici …",
    "placeholder-french": "Entrer ici …",
    "placeholder-german": "Entrer ici …",
    "placeholder-time-end": "Heure de fin",
    "placeholder-time-start": "Heure de début",
    "success": "Créé avec succès",
    "title": "Créer des news"
  },
  "gpt-config": {
    "default": "Défaut",
    "active": "Oui",
    "inactive": "Non",
    "title": "Paramètres GPT & test API",
    "api-key": "API Key",
    "organization": "Organisation",
    "model": "Modèle de langage API",
    "model-fetch-error": "Clé API ou organisation mal configurée, les modèles de langue ne sont pas disponibles.",
    "max-tokens": "Consommation maximale de jetons",
    "temperature": "Température",
    "top-percentage": "Nucleus Sampling",
    "logprobs": "Nombre de probabilités",
    "echo": "Répéter la saisie",
    "stop": "Mots d'arrêt",
    "add-stop": "Ajouter un mot d'arrêt",
    "presence-penalty": "Facteur de changement de sujet",
    "frequence-penalty": "Facteur de répétition",
    "logit-bias": "Modifier la pondération des jetons",
    "add-logit-bias": "Ajouter un tokenid",
    "logit-value": "Modifier la pondération",
    "next": "Continuer",
    "previous": "Retour",
    "save": "Enregistrer",
    "end": "Fin",
    "header-settings": "Paramètres de l'API GPT",
    "header-restrictions": "Limitation de l'API GPT",
    "header-metrics": "Statistiques de l'API GPT",
    "restrict-active": "API activée",
    "restrict-usage": "Groupe d'utilisateurs",
    "restrict-usage-registered-mods": "Modérateurs enregistrés",
    "restrict-usage-registered-users": "Utilisateurs enregistrés",
    "restrict-usage-all": "Tous les",
    "restrict-ip-filter": "Filtre IP",
    "restrict-add-ip-filter": "Ajouter un sous-réseau",
    "restrict-end-date": "Fin de l'API",
    "restrict-platform-accumulated": "Plate-forme : Max. Jeton",
    "restrict-platform-week": "Plate-forme : Max. Jetons / semaine",
    "restrict-platform-day": "Plate-forme : Max. Jetons / jour",
    "restrict-user-accumulated": "Utilisateur : Max. Jeton",
    "restrict-user-week": "Utilisateur : Max. Jetons / semaine",
    "restrict-user-day": "Utilisateur : Max. Jetons / jour",
    "save-error": "N'a pas pu enregistrer les données !",
    "load-error": "Impossible de charger la configuration !",
    "load-stats-error": "Je n'ai pas pu charger les statistiques !",
    "stats-message": "La plateforme a consommé au total {{all}}.\nDont {{week}} cette semaine et {{day}} ce jour.\nLa dernière utilisation a eu lieu le {{date}}.",
    "prompt-type": "Jeton pour la demande",
    "completion-type": "Jeton pour la distribution",
    "boxplot-message": "La médiane {{médiane}} {{type}} par requête a été consommée, avec 50% des données entre les jetons {{inférieurs}} et {{supérieurs}}. tokens. Parmi les {{comptes}} Requêtes, {{lowerStray}} en bas et {{upperStray}} en haut sont arrachées.",
    "api-key-and-model-required": "* La clé API et le modèle de langue sont nécessaires pour que l'API soit prise en charge de manière basique. Le 'text-davinci-003' (modèle de langue) donne actuellement les meilleurs résultats.",
    "temperature-and-top-p-exclusive": "* Il convient d'adapter soit la température, soit le prélèvement des noyaux. Mais pas les deux.",
    "temperature-determinism": "** Même si la valeur est à 0, d'autres réponses peuvent être générées !",
    "max-tokens-cap": "* Le nombre maximum de jetons dépend du modèle de langage, les plus récents peuvent en générer 4096, alors que les anciens ne peuvent en générer que 2048.",
    "penalty-info": "* Les pénalités de 0,1 à 1,0 suppriment les sujets / tokens similaires. Les valeurs supérieures à 1 suppriment presque totalement les tokens similaires, mais la qualité en pâtit.",
    "help-general": "L'API GPT met à disposition une intelligence artificielle qui effectue la complétion de texte. L'IA répond à des questions de classification, de connaissance et autres. L'IA possède une entrée et fournit au moins une sortie.",
    "help-api-key": "La clé API attribue les demandes à un compte. Ainsi, la consommation et les coûts peuvent être calculés et affichés dans le compte OpenAI.",
    "help-organization": "L'organisation est une possibilité optionnelle de faire facturer la consommation par une organisation plutôt que directement par son propre compte OpenAI.",
    "help-model": "Le modèle linguistique détermine la meilleure façon d'accomplir certaines tâches. En outre, il permet de choisir des modèles moins coûteux.",
    "help-max-tokens": "Le nombre maximal de jetons à utiliser pour générer *toutes* les dépenses. L'entrée est alors omise.",
    "help-temperature": "La température permet de définir si un risque élevé est autorisé ou si des dépenses presque déterministes sont souhaitées. 1 signifie un risque élevé, 0 signifie presque aucun risque.",
    "help-top-percentage": "Limite les jetons de sorte que seuls les jetons avec les meilleures probabilités soient sélectionnés. Si la valeur est de 0.1, les 10 % les plus élevés seront sélectionnés.",
    "help-logprobs": "Donne tous les tokens qui étaient les plus probables, ainsi que ceux qui ont été sélectionnés. Le nombre des plus probables est toutefois limité à 5.",
    "help-echo": "L'entrée est jointe en tant que texte précédant chaque sortie.",
    "help-stop": "Les mots d'arrêt sont une possibilité supplémentaire de limiter les entrées. De plus, ils peuvent être utilisés comme éléments de structuration lors de la saisie.",
    "help-presence-penalty": "Supprime ou renforce la répétition des jetons. Les valeurs plus élevées favorisent les nouveaux thèmes.",
    "help-frequency-penalty": "Supprime ou renforce la répétition des jetons. Des valeurs plus élevées suppriment les phrases similaires.",
    "help-logit-bias": "Modifie les probabilités des tokens. Les valeurs de -1 à 1 diminuent ou augmentent la probabilité, tandis que -100 et 100 bannissent les tokens ou les sélectionnent de manière exclusive lorsqu'ils apparaissent.",
    "help-trial-code": "Code d'activation de l'API globale pour les salles.",
    "trial-code": "Code d'activation de l'étude"
  },
  "gpt-chat": {
    "optin-accept": "Accepter",
    "optin-reject": "Refuser",
    "enter-conversation-text": "Chat avec GPT …",
    "send": "Envoyer",
    "empty-conversation": "Vider l'historique",
    "input-forbidden": "Saisie interdite, veuillez vérifier les paramètres de l'API GPT.",
    "no-api-setup": "La clé d'API ou le modèle de langage n'a pas été défini.",
    "greetings": {
      "text-davinci-003": [
        {
          "key": "École primaire",
          "value": "Tu es dans la salle de chat appelée \"Français\" et le sujet est la poésie. Explique la question suivante au niveau d'un élève d'une école primaire.\nElève : Qu'est-ce que les haïkus?\nTu : "
        },
        {
          "key": "École secondaire",
          "value": "Tu es dans la salle de chat appelée \"Histoire\" et le sujet est les années folles. Explique, au niveau d'un élève de terminale, la question suivante.\nElève : Que dit le plan Dawes?\nTu : "
        },
        {
          "key": "Université",
          "value": "Tu es dans la salle de chat appelée \"Algorithmes et structures de données\" et le sujet est les structures de données simples. Explique la question suivante au niveau d'un étudiant en informatique de deuxième année.\nEtudiant : Y a-t-il un gain de performance si l'on combine une liste liée et une liste de tableaux ? Il serait en effet imaginable de pouvoir lier des tableaux, ou est-ce que je me trompe?\nTu : "
        }
      ],
      "code-davinci-002": [
        {
          "key": "Web",
          "value": "<|endoftext|>/* I start with a blank HTML page, and incrementally modify it via <script> injection. Written for Chrome. */\n/* Command: Add \"Hello World\", by adding an HTML DOM node */\nvar helloWorld = document.createElement('div');\nhelloWorld.innerHTML = 'Hello World';\ndocument.body.appendChild(helloWorld);\n/* Command: Clear the page. */\nwhile (document.body.firstChild) {\n  document.body.removeChild(document.body.firstChild);\n}\n\n/* Command: Display this image of a cat: https://bit.ly/3fsc0rH */\n"
        }
      ],
      "davinci-instruct-beta:2.0.0": [
        {
          "key": "Smalltalk",
          "value": "Cette matière est démotivante. As-tu des astuces pour encourager et être plus actif ?"
        }
      ]
    },
    "refresh": "Générer à nouveau la sortie",
    "token-info": "Tokens (saisie / conversation / total) : {{promptTokens}} / {{conversationTokens}} / {{allTokens}}",
    "use-case": "Cas d'utilisation",
    "use-case-tooltip": "Sélection d'un cas d'utilisation spécifique pour de meilleures réponses.",
    "use-case-answer-questions": "Réponse aux questions",
    "use-case-tooltip-answer-questions": "Très efficace si de bonnes questions ou tâches (par ex. traduction et résumé) sont posées. Fournit généralement les meilleures réponses textuelles.",
    "use-case-code": "Compréhension du code & génération",
    "use-case-tooltip-code": "Très bon dans le domaine de la compréhension et de la génération de code. A un contexte plus large que les modèles de langage.",
    "use-case-chat": "Chat/Conversations",
    "use-case-tooltip-chat": "Efficace pour les questions ouvertes, où des demandes de précisions sont nécessaires. N'offre pas de résultats aussi précis que les réponses aux questions."
  }
}
