{
  "overview": {
    "motd": "Globale Ankündigungen",
    "gpt": "GPT-Einstellungen",
    "gpt-chat": "Chat mit GPT"
  },
  "create-motd": {
    "create": "Erstellen",
    "english": "Englischer Text",
    "error": "Ein Fehler ist aufgetreten!",
    "french": "Französischer Text",
    "german": "Deutscher Text",
    "label": "Anfangs- und Enddatum",
    "placeholder-date-end": "Enddatum",
    "placeholder-date-start": "Anfangsdatum",
    "placeholder-english": "Hier eingeben …",
    "placeholder-french": "Hier eingeben …",
    "placeholder-german": "Hier eingeben …",
    "placeholder-time-end": "Endzeit",
    "placeholder-time-start": "Anfangszeit",
    "success": "News erfolgreich erstellt",
    "title": "Aktuelle News erstellen"
  },
  "gpt-config": {
    "default": "Standard",
    "active": "Ja",
    "inactive": "Nein",
    "title": "GPT-Einstellungen & API-Test",
    "api-key": "API Key",
    "organization": "Organisation",
    "model": "API-Sprachmodell",
    "model-fetch-error": "API Key oder Organisation nicht korrekt konfiguriert, Sprach-Modelle sind nicht verfügbar.",
    "max-tokens": "Maximaler Tokenverbrauch",
    "temperature": "Temperatur",
    "top-percentage": "Nucleus Sampling",
    "logprobs": "Anzahl Wahrscheinlichkeiten",
    "echo": "Eingabe wiederholen",
    "stop": "Stoppwörter",
    "add-stop": "Stoppwort hinzufügen",
    "presence-penalty": "Faktor für Themenwechsel",
    "frequence-penalty": "Faktor für Wiederholungen",
    "logit-bias": "Tokengewichtung verändern",
    "add-logit-bias": "Token-ID hinzufügen",
    "logit-value": "Gewichtung ändern",
    "next": "Weiter",
    "previous": "Zurück",
    "save": "Speichern",
    "end": "Ende",
    "header-settings": "GPT API Einstellungen",
    "header-restrictions": "GPT API Beschränkung",
    "header-metrics": "GPT API Statistiken",
    "restrict-active": "API aktiviert",
    "restrict-usage": "Benutzergruppe",
    "restrict-usage-registered-mods": "Registrierte Moderatoren",
    "restrict-usage-registered-users": "Registrierte Nutzer",
    "restrict-usage-all": "Alle",
    "restrict-ip-filter": "IP-Filter",
    "restrict-add-ip-filter": "Subnetz hinzufügen",
    "restrict-end-date": "API Ende",
    "restrict-platform-accumulated": "Plattform: Max. Token",
    "restrict-platform-week": "Plattform: Max. Token / Woche",
    "restrict-platform-day": "Plattform: Max. Token / Tag",
    "restrict-user-accumulated": "Nutzer: Max. Token",
    "restrict-user-week": "Nutzer: Max. Token / Woche",
    "restrict-user-day": "Nutzer: Max. Token / Tag",
    "save-error": "Konnte Daten nicht speichern!",
    "load-error": "Konnte Konfiguration nicht laden!",
    "load-stats-error": "Konnte Statistiken nicht laden!",
    "stats-message": "Die Plattform hat insgesamt {{all}} Tokens verbraucht.\nDavon {{week}} diese Woche und {{day}} Tokens an diesem Tag.\nDie letzte Nutzung fand am {{date}} statt.",
    "prompt-type": "Token für die Anfrage",
    "completion-type": "Token für die Ausgabe",
    "boxplot-message": "Es wurden im Median {{median}} {{type}} pro Request verbraucht, dabei befanden sich 50% der Daten zwischen {{lower}} Tokens und {{upper}} Tokens. Von {{count}} Requests sind {{lowerStray}} unterhalb und {{upperStray}} oberhalb ausgerissen.",
    "api-key-and-model-required": "* Der API Key und das Sprachmodell wird benötigt, damit die API grundlegend unterstützt wird. 'text-davinci-003' (Sprachmodell) liefert derzeit die besten Resultate.",
    "temperature-and-top-p-exclusive": "* Entweder sollte die Temperatur oder das Nucleus Sampling angepasst werden. Jedoch nicht beides.",
    "temperature-determinism": "** Selbst wenn der Wert auf 0 ist, können andere Antworten generiert werden!",
    "max-tokens-cap": "* Die maximalen Tokens hängen von dem Sprachmodell ab, die neusten können 4096, während die alten nur 2048 Tokens erzeugen können.",
    "penalty-info": "* Strafen von 0.1 bis 1.0 unterdrücken ähnliche Themen / Tokens. Werte über 1 unterdrücken ähnliche Tokens fast völlig, jedoch leidet darunter die Qualität.",
    "help-general": "Die GPT API stellt eine künstliche Intelligenz bereit, die Text-Vervollständigung durchführt. Dabei beantwortet die KI Klassifizierungs-, Wissens- und weitere Fragen. Die KI besitzt eine Eingabe und liefert mindestens eine Ausgabe.",
    "help-api-key": "Der API Schlüssel ordnet die Anfragen einem Account zu. So können Verbrauch und Kosten im OpenAI Konto berechnet und angezeigt werden",
    "help-organization": "Die Organisation ist eine optionale Möglichkeit den Verbrauch über eine Organisation abrechnen zu lassen, anstatt direkt über den eigenen OpenAI-Account.",
    "help-model": "Das Sprachmodell entscheidet darüber wie bestimmte Aufgaben am besten gelöst werden. Des Weiteren gibt es einem die Möglichkeit kostengünstigere Modelle auszuwählen.",
    "help-max-tokens": "Die maximale Anzahl an Tokens die verwendet werden soll um *alle* Ausgaben zu generieren. Die Eingabe wird dabei ausgelassen.",
    "help-temperature": "Die Temperatur erlaubt die Einstellung, ob ein hohes Risiko erlaubt ist oder ob nahezu deterministische Ausgaben gewünscht sind. 1 meint hohes Risiko, 0 fast kein Risiko.",
    "help-top-percentage": "Schränkt die Tokens ein, sodass nur die Tokens mit den Top-Wahrscheinlichkeiten ausgewählt werden. Bei einem Wert von 0.1 werden die Top 10% ausgewählt.",
    "help-logprobs": "Gibt alle Tokens aus, die am wahrscheinlichsten waren, sowie die ausgewählten. Die Anzahl der wahrscheinlichsten ist jedoch auf 5 begrenzt.",
    "help-echo": "Die Eingabe wird als vorausgehender Text einer jeden Ausgabe angehangen.",
    "help-stop": "Stopwörter sind eine zusätzliche Möglichkeit Eingaben zu begrenzen. Des Weiteren können sie als Strukturierungelemente bei der Eingabe verwendet werden.",
    "help-presence-penalty": "Unterdrückt oder verstärkt die Wiederholung von Tokens. Höhere Werte fördern neue Themen.",
    "help-frequency-penalty": "Unterdrückt oder verstärkt die Wiederholung von Tokens. Höhere Werte unterdrücken ähnliche Satzstellungen.",
    "help-best-of": "Generiert für jede Ausgabe mehrere Ausgaben und nimmt davon die, die am wahrscheinlichsten zu der Eingabe passt.",
    "help-logit-bias": "Verändert die Wahrscheinlichkeiten für Tokens. Werte von -1 bis 1  erniedrigen oder erhöhen die Wahrscheinlichkeit, während -100 und 100 die Tokens bannen oder wenn sie vorkommen, exklusiv selektieren.",
    "help-trial-code": "Code für die Aktivierung der globalen API für Räume.",
    "trial-code": "Studien-Aktivierungscode"
  },
  "gpt-chat": {
    "enter-conversation-text": "Chat mit GPT …",
    "send": "Senden",
    "empty-conversation": "Verlauf leeren",
    "optin-accept": "Akzeptieren",
    "optin-reject": "Ablehnen",
    "input-forbidden": "Eingabe verboten, bitte prüfe die GPT API Einstellungen.",
    "no-api-setup": "Der API Schlüssel oder das Sprachmodell wurden nicht gesetzt.",
    "greetings": {
      "text-davinci-003": [
        {
          "key": "Grundschule",
          "value": "Du bist im Chat-Raum namens \"Deutsch\" und es geht um das Thema Gedichte. Erkläre auf dem Niveau eines Schülers einer Grundschule folgende Frage.\nSchüler: Was sind Haikus?\nDu: "
        },
        {
          "key": "Gymnasium",
          "value": "Du bist im Chat-Raum namens \"Geschichte\" und es geht um das Thema der goldenen Zwanziger. Erkläre auf dem Niveau eines Abitur-Schülers folgende Frage.\nSchüler: Was besagt der Dawes-Plan?\nDu: "
        },
        {
          "key": "Hochschule",
          "value": "Du bist im Chat-Raum namens \"Algorithmen und Datenstrukturen\" und es geht um das Thema simple Datenstrukturen. Erkläre auf dem Niveau eines Informatik-Studenten im 2. Semester folgende Frage.\nStudent: Gibt es ein Performance-Gewinn, wenn man eine verlinkte Liste und eine Array Liste kombiniert? Es wäre doch vorstellbar, dass man Arrays verlinken könnte, oder liege ich dort falsch?\nDu: "
        }
      ],
      "code-davinci-002": [
        {
          "key": "Web",
          "value": "<|endoftext|>/* I start with a blank HTML page, and incrementally modify it via <script> injection. Written for Chrome. */\n/* Command: Add \"Hello World\", by adding an HTML DOM node */\nvar helloWorld = document.createElement('div');\nhelloWorld.innerHTML = 'Hello World';\ndocument.body.appendChild(helloWorld);\n/* Command: Clear the page. */\nwhile (document.body.firstChild) {\n  document.body.removeChild(document.body.firstChild);\n}\n\n/* Command: Display this image of a cat: https://bit.ly/3fsc0rH */\n"
        }
      ],
      "davinci-instruct-beta:2.0.0": [
        {
          "key": "Smalltalk",
          "value": "Das Fach ist demotivierend. Hast du Tricks zum aufmuntern und aktiver werden?"
        }
      ]
    },
    "refresh": "Ausgabe erneut generieren",
    "token-info": "Tokens (Eingabe / Chat / Gesamt): {{promptTokens}} / {{conversationTokens}} / {{allTokens}}",
    "use-case": "Anwendungsfall",
    "use-case-tooltip": "Auswahl eines speziellen Anwendungsfalles für bessere Antworten.",
    "use-case-answer-questions": "Beantwortung von Fragen",
    "use-case-tooltip-answer-questions": "Sehr effektiv, wenn gute Fragen oder Aufgaben (z. B. Übersetzung und Zusammenfassung) gestellt werden. Liefert meist die besten Text-Antworten.",
    "use-case-code": "Code-Verständnis & Generierung",
    "use-case-tooltip-code": "Sehr gut im Bereich von Code-Verständnis und Generierung. Hat einen größeren Kontext als Sprachmodelle.",
    "use-case-chat": "Chat/Konversationen",
    "use-case-tooltip-chat": "Effektiv für offene Fragen, wo nachfragen benötigt werden. Bietet nicht so genaue Ergebnisse, wie die Beantwortung von Fragen."
  }
}
